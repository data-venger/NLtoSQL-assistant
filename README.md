# âš¡ Warehouse SQL Assistant

AI-powered SQL assistant for banking data analysis. Ask questions in natural language â€” the AI generates SQL, executes it, and explains the results.

Built with a **RAG (Retrieval-Augmented Generation)** architecture: your question is embedded, matched against database schema vectors, and used to generate context-aware SQL queries.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚     Backend      â”‚    â”‚     Ollama      â”‚
â”‚   (React+Vite)  â”‚â—„â”€â”€â–ºâ”‚    (Flask)       â”‚â—„â”€â”€â–ºâ”‚   (Local LLM)   â”‚
â”‚   Port: 5173    â”‚    â”‚   Port: 5001     â”‚    â”‚  Port: 11434    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                       â”‚
              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”
              â”‚PostgreSQL  â”‚          â”‚ Qdrant  â”‚
              â”‚Port: 5432  â”‚          â”‚Port:6333â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Component | Role |
|-----------|------|
| **Frontend** | React + Vite UI with chat interface, SQL editor, schema explorer |
| **Backend** | Flask API â€” orchestrates the RAG pipeline |
| **PostgreSQL** | Banking database with 8 tables of sample data |
| **Qdrant** | Vector database storing schema embeddings for RAG search |
| **Ollama** | Local LLM (llama3.2) for SQL generation and response formatting |

---

## Features

| Feature | Description |
|---------|-------------|
| ğŸ’¬ **Natural Language Chat** | Ask questions in plain English, get SQL + results |
| âŒ¨ï¸ **Direct SQL Mode** | Write and execute SQL queries directly |
| ğŸ“Š **Schema Explorer** | Browse all tables and columns in the sidebar |
| ğŸ• **Query History** | Re-run past queries with one click |
| ğŸ”„ **Column Sorting** | Click column headers to sort results |
| ğŸ“„ **Pagination** | Navigate large result sets (15 rows/page) |
| ğŸ“¥ **CSV Export** | Download any result as a CSV file |
| ğŸŒ™ **Dark/Light Mode** | Toggle theme, respects OS preference |
| ğŸ”’ **Read-Only Safety** | Only SELECT queries allowed, with timeout protection |

---

## Prerequisites

Make sure you have the following installed before starting:

| Tool | Version | Check Command | Install |
|------|---------|---------------|---------|
| **Docker** | 20+ | `docker --version` | [docker.com](https://docs.docker.com/get-docker/) |
| **Docker Compose** | v2+ | `docker compose version` | Included with Docker Desktop |
| **Python** | 3.10+ | `python3 --version` | [python.org](https://www.python.org/downloads/) |
| **Node.js** | 18+ | `node --version` | [nodejs.org](https://nodejs.org/) |
| **npm** | 9+ | `npm --version` | Included with Node.js |

---

## Setup (First Time)

### Step 1: Clone / Navigate to the Project

```bash
cd /path/to/warehouse_sql_assistant
```

### Step 2: Start Database Services (Docker)

```bash
docker-compose up -d postgres qdrant
```

This starts:
- **PostgreSQL** on port `5432` â€” auto-creates the banking database with 8 tables and sample data
- **Qdrant** on port `6333` â€” vector database for schema embeddings

Verify they're running:
```bash
docker ps
```
You should see `wsa-postgres` (healthy) and `wsa-qdrant` (running).

### Step 3: Set Up the Backend

```bash
cd backend

# Create a Python virtual environment (first time only)
python3 -m venv venv

# Activate the virtual environment
source venv/bin/activate

# Install Python dependencies
pip install -r requirements.txt
```

> âš ï¸ **IMPORTANT**: You MUST run `source venv/bin/activate` every time you open a new terminal before running any Python commands. If you see `pip: command not found` or `ModuleNotFoundError`, you forgot to activate the venv.

### Step 4: Start the Backend Server

```bash
# Make sure venv is activated (you should see (venv) in your prompt)
source venv/bin/activate

# Start Flask server
python app.py
```

The backend runs on **http://localhost:5001**.

Verify it's working:
```bash
# In a separate terminal
curl http://localhost:5001/api/health
# Should return: {"status": "ok"}
```

### Step 5: Install & Start Ollama (AI/LLM)

**Install Ollama** (first time only):
```bash
# macOS â€” download from https://ollama.com/download
# Or via the install script:
curl -fsSL https://ollama.com/install.sh | sh
```

**Start the Ollama server:**
```bash
ollama serve
```

> On macOS, if `ollama` is not in your PATH, use the full path:
> ```bash
> /Applications/Ollama.app/Contents/Resources/ollama serve
> ```

**Pull the LLM model** (first time only â€” ~2GB download):
```bash
# In a separate terminal
ollama pull llama3.2
```

Verify Ollama is running:
```bash
curl http://localhost:11434/api/tags
# Should return a JSON with the llama3.2 model listed
```

### Step 6: Seed Schema Embeddings (First Time Only)

This populates Qdrant with vector embeddings of the database schema so the AI knows which tables/columns exist:

```bash
cd backend
source venv/bin/activate
python ../scripts/seed_schemas.py
```

Expected output:
```
ğŸ”„ Seeding schema embeddings into Qdrant...
âœ… Embedded 8 table schemas successfully!
ğŸ“Š Verified 8 schemas in Qdrant
```

### Step 7: Install & Start the Frontend

```bash
cd frontend

# Install Node dependencies (first time only)
npm install

# Start the dev server
npm run dev
```

The frontend runs on **http://localhost:5173**.

### Step 8: Open the App! ğŸ‰

Open your browser and go to: **http://localhost:5173**

Try typing: *"How many customers do we have?"*

---

## Running After First Setup

Once everything is set up, here's the quick-start for subsequent runs:

```bash
# Terminal 1 â€” Docker (if not already running)
cd /path/to/warehouse_sql_assistant
docker-compose up -d postgres qdrant

# Terminal 2 â€” Backend
cd /path/to/warehouse_sql_assistant/backend
source venv/bin/activate
python app.py

# Terminal 3 â€” Ollama
ollama serve
# Or: /Applications/Ollama.app/Contents/Resources/ollama serve

# Terminal 4 â€” Frontend
cd /path/to/warehouse_sql_assistant/frontend
npm run dev
```

Then open **http://localhost:5173**.

---

## Environment Variables

The `.env` file in the project root controls all configuration. Default values work out of the box for local development:

```env
# Database
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=banking_db
DATABASE_USER=postgres
DATABASE_PASSWORD=postgres

# AI Services
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
QDRANT_URL=http://localhost:6333
LLM_PROVIDER=ollama          # Options: ollama, gemini

# If using Gemini instead of Ollama:
# GEMINI_API_KEY=your-api-key-here
# LLM_PROVIDER=gemini

# Security
SECRET_KEY=dev-secret-key-change-in-production
QUERY_TIMEOUT=30
MAX_QUERY_ROWS=1000

# Flask
FLASK_DEBUG=true
```

---

## Database Schema

The banking database contains 8 interconnected tables:

| Table | Rows | Description |
|-------|------|-------------|
| `branches` | 5 | Bank branch locations |
| `customers` | 20 | Customer demographics & financials |
| `accounts` | 30 | Checking, savings, money market accounts |
| `transactions` | 50+ | Deposits, withdrawals, transfers |
| `credit_cards` | 8 | Card details, limits, balances |
| `credit_card_transactions` | 14 | Card purchases and payments |
| `loans` | 10 | Mortgage, personal, auto, business loans |
| `loan_payments` | 20+ | Payment records with principal/interest |

---

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/health` | Health check |
| `POST` | `/api/chat` | Send a natural language query (RAG pipeline) |
| `GET` | `/api/database/test` | Test database connection |
| `GET` | `/api/database/tables` | List all tables with row counts |
| `GET` | `/api/database/tables/<name>` | Get column details for a table |
| `POST` | `/api/database/execute` | Execute a SQL query directly |
| `POST` | `/api/embeddings/embed` | Embed a schema into Qdrant |
| `POST` | `/api/embeddings/search` | Search similar schemas |
| `GET` | `/api/embeddings/schemas` | List all stored schemas |

---

## Troubleshooting

### `pip: command not found` or `ModuleNotFoundError`
You forgot to activate the virtual environment:
```bash
cd backend
source venv/bin/activate
```

### `Port 5001 is in use`
The backend is already running. Either:
- Use the existing instance, or
- Kill it: `lsof -ti:5001 | xargs kill -9`

### `Port 5000 is in use` (macOS)
macOS AirPlay Receiver uses port 5000. Our backend uses **port 5001** to avoid this conflict.

### `Address already in use` for Ollama (port 11434)
Ollama is already running. Check with:
```bash
curl http://localhost:11434/api/tags
```
If it responds, Ollama is fine â€” no need to start it again.

### Docker containers not starting
```bash
# Check container status
docker ps -a

# View logs
docker logs wsa-postgres
docker logs wsa-qdrant

# Restart from scratch
docker-compose down -v
docker-compose up -d postgres qdrant
```
> âš ï¸ `docker-compose down -v` deletes all data. You'll need to re-seed schemas after.

### Chat returns errors but Direct SQL works
Make sure:
1. Ollama is running (`curl http://localhost:11434/api/tags`)
2. The llama3.2 model is pulled (`ollama list` should show it)
3. Schema embeddings are seeded (run `python ../scripts/seed_schemas.py`)

### Frontend shows "Disconnected"
The backend isn't reachable. Make sure:
1. Backend is running on port 5001
2. Vite proxy is configured for port 5001 (check `frontend/vite.config.js`)

---

## Project Structure

```
warehouse_sql_assistant/
â”œâ”€â”€ .env                          # Environment variables
â”œâ”€â”€ .env.example                  # Environment template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml            # PostgreSQL + Qdrant services
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app.py                    # Flask entry point
â”‚   â”œâ”€â”€ config.py                 # Configuration loader
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chat.py               # RAG pipeline API
â”‚   â”‚   â”œâ”€â”€ database.py           # Database query API
â”‚   â”‚   â””â”€â”€ embeddings.py         # Schema embedding API
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ database_service.py   # Safe SQL execution
â”‚       â”œâ”€â”€ embedding_service.py  # Qdrant + SentenceTransformers
â”‚       â””â”€â”€ llm_client.py         # Ollama/Gemini LLM client
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.jsx               # Main application
â”‚       â”œâ”€â”€ api.js                # API client
â”‚       â”œâ”€â”€ index.css             # Design system
â”‚       â”œâ”€â”€ main.jsx              # React entry
â”‚       â””â”€â”€ components/
â”‚           â”œâ”€â”€ QueryHistory.jsx  # Query history sidebar
â”‚           â”œâ”€â”€ ResultTable.jsx   # Sortable, paginated results
â”‚           â”œâ”€â”€ SchemaExplorer.jsx # Database schema browser
â”‚           â””â”€â”€ SqlBlock.jsx      # SQL display with highlighting
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 01_banking_schema.sql     # Database DDL
â”‚   â””â”€â”€ 02_banking_data.sql       # Sample data
â”‚
â””â”€â”€ scripts/
    â””â”€â”€ seed_schemas.py           # Seed Qdrant with schema embeddings
```

---

## Tech Stack

| Layer | Technology |
|-------|-----------|
| Frontend | React 18 + Vite 6 |
| Backend | Flask (Python 3.11) |
| LLM | Ollama (llama3.2) / Gemini API |
| Vector DB | Qdrant |
| Database | PostgreSQL 15 |
| Embeddings | SentenceTransformers (all-MiniLM-L6-v2) |
